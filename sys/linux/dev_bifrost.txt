# Generated on android14-gs-pixel-5.15-udc-d1

include <gpu/mali_kbase/mali_kbase_debug.h>
include <gpu/common/include/uapi/gpu/arm/midgard/mali_kbase_hwcnt_reader.h>
include <gpu/common/include/uapi/gpu/arm/midgard/mali_kbase_ioctl.h>
include <gpu/common/include/uapi/gpu/arm/midgard/mali_base_kernel.h>
include <uapi/linux/fcntl.h>

resource fd_bifrost[fd]
resource gpu_addr[int64]: BASEP_MEM_INVALID_HANDLE, BASEP_MEM_WRITE_ALLOC_PAGES_HANDLE
resource user_addr[int64]: -1
resource fd_fence[fd]
resource fd_hwcnt[fd]
# LIZ TODO: Investigate fd_prfcnt
# resource fd_prfcnt[fd]

openat$bifrost(fd const[AT_FDCWD], file ptr[in, string["/dev/bifrost"]], flags flags[open_flags], mode const[0]) fd_bifrost
# Device name on Android
openat$mali(fd const[AT_FDCWD], file ptr[in, string["/dev/mali0"]], flags flags[open_flags], mode const[0]) fd_bifrost

mmap$bifrost(addr const[0], len len[addr], prot flags[mmap_prot], flags flags[mmap_flags], fd fd_bifrost, offset fileoff) user_addr
_ = __NR_mmap2

ioctl$KBASE_IOCTL_READ_USER_PAGE(fd fd_bifrost, cmd const[KBASE_IOCTL_READ_USER_PAGE], arg ptr[inout, kbase_ioctl_read_user_page])
ioctl$KBASE_IOCTL_MEM_ALLOC_EX(fd fd_bifrost, cmd const[KBASE_IOCTL_MEM_ALLOC_EX], arg ptr[inout, kbase_ioctl_mem_alloc_ex])
ioctl$KBASE_IOCTL_CS_CPU_QUEUE_DUMP(fd fd_bifrost, cmd const[KBASE_IOCTL_CS_CPU_QUEUE_DUMP], arg ptr[in, kbase_ioctl_cs_cpu_queue_info])
ioctl$KBASE_IOCTL_CS_GET_GLB_IFACE(fd fd_bifrost, cmd const[KBASE_IOCTL_CS_GET_GLB_IFACE], arg ptr[inout, kbase_ioctl_cs_get_glb_iface])
ioctl$KBASE_IOCTL_CS_TILER_HEAP_TERM(fd fd_bifrost, cmd const[KBASE_IOCTL_CS_TILER_HEAP_TERM], arg ptr[in, kbase_ioctl_cs_tiler_heap_term])
ioctl$KBASE_IOCTL_CS_TILER_HEAP_INIT_1_13(fd fd_bifrost, cmd const[KBASE_IOCTL_CS_TILER_HEAP_INIT_1_13], arg ptr[inout, kbase_ioctl_cs_tiler_heap_init_1_13])
ioctl$KBASE_IOCTL_CS_TILER_HEAP_INIT(fd fd_bifrost, cmd const[KBASE_IOCTL_CS_TILER_HEAP_INIT], arg ptr[inout, kbase_ioctl_cs_tiler_heap_init])
ioctl$KBASE_IOCTL_KCPU_QUEUE_ENQUEUE(fd fd_bifrost, cmd const[KBASE_IOCTL_KCPU_QUEUE_ENQUEUE], arg ptr[in, kbase_ioctl_kcpu_queue_enqueue])
ioctl$KBASE_IOCTL_KCPU_QUEUE_DELETE(fd fd_bifrost, cmd const[BASE_IOCTL_KCPU_QUEUE_DELETE], arg ptr[in, kbase_ioctl_kcpu_queue_delete])
ioctl$KBASE_IOCTL_KCPU_QUEUE_CREATE(fd fd_bifrost, cmd const[BASE_IOCTL_KCPU_QUEUE_CREATE], arg ptr[out, kbase_ioctl_kcpu_queue_new])
ioctl$KBASE_IOCTL_CS_EVENT_SIGNAL(fd fd_bifrost, cmd const[KBASE_IOCTL_CS_EVENT_SIGNAL])
ioctl$KBASE_IOCTL_CS_QUEUE_GROUP_TERMINATE(fd fd_bifrost, cmd const[KBASE_IOCTL_CS_QUEUE_GROUP_TERMINATE], arg ptr[in, kbase_ioctl_cs_queue_terminate])
ioctl$KBASE_IOCTL_CS_QUEUE_GROUP_CREATE(fd fd_bifrost, cmd const[KBASE_IOCTL_CS_QUEUE_GROUP_CREATE], arg ptr[inout, kbase_ioctl_cs_queue_group_create])
ioctl$KBASE_IOCTL_CS_QUEUE_GROUP_CREATE_1_6(fd fd_bifrost, cmd const[KBASE_IOCTL_CS_QUEUE_GROUP_CREATE_1_6], arg ptr[inout, kbase_ioctl_cs_queue_group_create_1_6])
ioctl$KBASE_IOCTL_CS_QUEUE_TERMINATE(fd fd_bifrost, cmd const[KBASE_IOCTL_CS_QUEUE_TERMINATE], arg ptr[in, kbase_ioctl_cs_queue_terminate])
ioctl$KBASE_IOCTL_CS_QUEUE_REGISTER_EX(fd fd_bifrost, cmd const[KBASE_IOCTL_CS_QUEUE_REGISTER_EX], arg ptr[in, kbase_ioctl_cs_queue_register_ex])
ioctl$KBASE_IOCTL_CS_QUEUE_BIND(fd fd_bifrost, cmd const[KBASE_IOCTL_CS_QUEUE_BIND], arg ptr[inout, kbase_ioctl_cs_queue_bind])
ioctl$KBASE_IOCTL_CS_QUEUE_KICK(fd fd_bifrost, cmd const[KBASE_IOCTL_CS_QUEUE_KICK], arg ptr[in, kbase_ioctl_cs_queue_kick])
ioctl$KBASE_IOCTL_CS_QUEUE_REGISTER(fd fd_bifrost, cmd const[KBASE_IOCTL_CS_QUEUE_REGISTER], arg ptr[in, base_ioctl_cs_queue_register])
ioctl$KBASE_IOCTL_VERSION_CHECK_RESERVED(fd fd_bifrost, cmd const[KBASE_IOCTL_VERSION_CHECK_RESERVED], arg ptr[inout, kbase_ioctl_version_check])
ioctl$KBASE_IOCTL_BUFFER_LIVENESS_UPDATE(fd fd_bifrost, cmd const[KBASE_IOCTL_BUFFER_LIVENESS_UPDATE], arg ptr[in, kbase_ioctl_buffer_liveness_update])
# LIZ TODO: Investicate return fd_prfcnt ioctl
ioctl$KBASE_IOCTL_KINSTR_PRFCNT_SETUP(fd fd_bifrost, cmd const[KBASE_IOCTL_KINSTR_PRFCNT_SETUP], arg ptr[inout, kbase_ioctl_kinstr_prfcnt_setup])
ioctl$KBASE_IOCTL_KINSTR_PRFCNT_ENUM_INFO(fd fd_bifrost, cmd const[KBASE_IOCTL_KINSTR_PRFCNT_ENUM_INFO], arg ptr[inout, kbase_ioctl_kinstr_prfcnt_enum_info])
ioctl$KBASE_IOCTL_SET_LIMITED_CORE_COUNT(fd fd_bifrost, cmd const[KBASE_IOCTL_SET_LIMITED_CORE_COUNT], arg ptr[in, kbase_ioctl_set_limited_core_count])
ioctl$KBASE_IOCTL_CONTEXT_PRIORITY_CHECK(fd fd_bifrost, cmd const[KBASE_IOCTL_CONTEXT_PRIORITY_CHECK], arg ptr[inout, kbase_ioctl_context_priority_check])

ioctl$KBASE_IOCTL_JOB_SUBMIT(fd fd_bifrost, cmd const[KBASE_IOCTL_JOB_SUBMIT], arg ptr[in, kbase_ioctl_job_submit])
ioctl$KBASE_IOCTL_POST_TERM(fd fd_bifrost, cmd const[KBASE_IOCTL_POST_TERM], arg const[0])
ioctl$KBASE_IOCTL_SOFT_EVENT_UPDATE(fd fd_bifrost, cmd const[KBASE_IOCTL_SOFT_EVENT_UPDATE], arg ptr[in, kbase_ioctl_soft_event_update])
ioctl$KBASE_IOCTL_VERSION_CHECK(fd fd_bifrost, cmd const[KBASE_IOCTL_VERSION_CHECK], arg ptr[inout, kbase_ioctl_version_check])
ioctl$KBASE_IOCTL_SET_FLAGS(fd fd_bifrost, cmd const[KBASE_IOCTL_SET_FLAGS], arg ptr[in, kbase_ioctl_set_flags])
ioctl$KBASE_IOCTL_GET_GPUPROPS(fd fd_bifrost, cmd const[KBASE_IOCTL_GET_GPUPROPS], arg ptr[inout, kbase_ioctl_get_gpuprops])
ioctl$KBASE_IOCTL_MEM_ALLOC(fd fd_bifrost, cmd const[KBASE_IOCTL_MEM_ALLOC], arg ptr[inout, kbase_ioctl_mem_alloc])
ioctl$KBASE_IOCTL_MEM_QUERY(fd fd_bifrost, cmd const[KBASE_IOCTL_MEM_QUERY], arg ptr[inout, kbase_ioctl_mem_query])
ioctl$KBASE_IOCTL_MEM_FREE(fd fd_bifrost, cmd const[KBASE_IOCTL_MEM_FREE], arg ptr[in, kbase_ioctl_mem_free])
ioctl$KBASE_IOCTL_HWCNT_READER_SETUP(fd fd_bifrost, cmd const[KBASE_IOCTL_HWCNT_READER_SETUP], arg ptr[in, kbase_ioctl_hwcnt_reader_setup]) fd_hwcnt
ioctl$KBASE_IOCTL_HWCNT_ENABLE(fd fd_bifrost, cmd const[KBASE_IOCTL_HWCNT_ENABLE], arg ptr[in, kbase_ioctl_hwcnt_enable])
ioctl$KBASE_IOCTL_HWCNT_DUMP(fd fd_bifrost, cmd const[KBASE_IOCTL_HWCNT_DUMP], arg const[0])
ioctl$KBASE_IOCTL_HWCNT_CLEAR(fd fd_bifrost, cmd const[KBASE_IOCTL_HWCNT_CLEAR], arg const[0])
ioctl$KBASE_IOCTL_HWCNT_SET(fd fd_bifrost, cmd const[KBASE_IOCTL_HWCNT_SET], arg ptr[inout, kbase_ioctl_hwcnt_values])
ioctl$KBASE_IOCTL_DISJOINT_QUERY(fd fd_bifrost, cmd const[KBASE_IOCTL_DISJOINT_QUERY], arg ptr[out, kbase_ioctl_disjoint_query])
ioctl$KBASE_IOCTL_GET_DDK_VERSION(fd fd_bifrost, cmd const[KBASE_IOCTL_GET_DDK_VERSION], arg ptr[inout, kbase_ioctl_get_ddk_version])
ioctl$KBASE_IOCTL_MEM_JIT_INIT_10_2(fd fd_bifrost, cmd const[KBASE_IOCTL_MEM_JIT_INIT_10_2], arg ptr[in, kbase_ioctl_mem_jit_init_10_2])
ioctl$KBASE_IOCTL_MEM_JIT_INIT_11_5(fd fd_bifrost, cmd const[KBASE_IOCTL_MEM_JIT_INIT_11_5], arg ptr[in, kbase_ioctl_mem_jit_init_11_5])
ioctl$KBASE_IOCTL_MEM_JIT_INIT(fd fd_bifrost, cmd const[KBASE_IOCTL_MEM_JIT_INIT], arg ptr[in, kbase_ioctl_mem_jit_init])
ioctl$KBASE_IOCTL_MEM_SYNC(fd fd_bifrost, cmd const[KBASE_IOCTL_MEM_SYNC], arg ptr[in, kbase_ioctl_mem_sync])
ioctl$KBASE_IOCTL_MEM_FIND_CPU_OFFSET(fd fd_bifrost, cmd const[KBASE_IOCTL_MEM_FIND_CPU_OFFSET], arg ptr[inout, kbase_ioctl_mem_find_cpu_offset])
ioctl$KBASE_IOCTL_GET_CONTEXT_ID(fd fd_bifrost, cmd const[KBASE_IOCTL_GET_CONTEXT_ID], arg ptr[out, kbase_ioctl_get_context_id])
ioctl$KBASE_IOCTL_TLSTREAM_ACQUIRE(fd fd_bifrost, cmd const[KBASE_IOCTL_TLSTREAM_ACQUIRE], arg ptr[in, kbase_ioctl_tlstream_acquire])
ioctl$KBASE_IOCTL_TLSTREAM_FLUSH(fd fd_bifrost, cmd const[KBASE_IOCTL_TLSTREAM_FLUSH], arg const[0])
ioctl$KBASE_IOCTL_MEM_COMMIT(fd fd_bifrost, cmd const[KBASE_IOCTL_MEM_COMMIT], arg ptr[in, kbase_ioctl_mem_commit])
ioctl$KBASE_IOCTL_MEM_ALIAS(fd fd_bifrost, cmd const[KBASE_IOCTL_MEM_ALIAS], arg ptr[inout, kbase_ioctl_mem_alias])
ioctl$KBASE_IOCTL_MEM_IMPORT(fd fd_bifrost, cmd const[KBASE_IOCTL_MEM_IMPORT], arg ptr[inout, kbase_ioctl_mem_import])
ioctl$KBASE_IOCTL_MEM_FLAGS_CHANGE(fd fd_bifrost, cmd const[KBASE_IOCTL_MEM_FLAGS_CHANGE], arg ptr[in, kbase_ioctl_mem_flags_change])
ioctl$KBASE_IOCTL_STREAM_CREATE(fd fd_bifrost, cmd const[KBASE_IOCTL_STREAM_CREATE], arg ptr[in, kbase_ioctl_stream_create]) fd_fence
ioctl$KBASE_IOCTL_FENCE_VALIDATE(fd fd_bifrost, cmd const[KBASE_IOCTL_FENCE_VALIDATE], arg ptr[in, kbase_ioctl_fence_validate])
ioctl$KBASE_IOCTL_MEM_PROFILE_ADD(fd fd_bifrost, cmd const[KBASE_IOCTL_MEM_PROFILE_ADD], arg ptr[in, kbase_ioctl_mem_profile_add])
ioctl$KBASE_IOCTL_STICKY_RESOURCE_MAP(fd fd_bifrost, cmd const[KBASE_IOCTL_STICKY_RESOURCE_MAP], arg ptr[in, kbase_ioctl_sticky_resource_map])
ioctl$KBASE_IOCTL_STICKY_RESOURCE_UNMAP(fd fd_bifrost, cmd const[KBASE_IOCTL_STICKY_RESOURCE_UNMAP], arg ptr[in, kbase_ioctl_sticky_resource_unmap])
ioctl$KBASE_IOCTL_MEM_FIND_GPU_START_AND_OFFSET(fd fd_bifrost, cmd const[KBASE_IOCTL_MEM_FIND_GPU_START_AND_OFFSET], arg ptr[inout, kbase_ioctl_mem_find_gpu_start_and_offset])
ioctl$KBASE_IOCTL_MEM_EXEC_INIT(fd fd_bifrost, cmd const[KBASE_IOCTL_MEM_EXEC_INIT], arg ptr[in, kbase_ioctl_mem_exec_init])
ioctl$KBASE_IOCTL_GET_CPU_GPU_TIMEINFO(fd fd_bifrost, cmd const[KBASE_IOCTL_GET_CPU_GPU_TIMEINFO], arg ptr[inout, kbase_ioctl_get_cpu_gpu_timeinfo])
ioctl$KBASE_HWCNT_READER_GET_HWVER(fd fd_hwcnt, cmd const[KBASE_HWCNT_READER_GET_HWVER], arg const[0])
ioctl$KBASE_HWCNT_READER_GET_BUFFER_SIZE(fd fd_hwcnt, cmd const[KBASE_HWCNT_READER_GET_BUFFER_SIZE], arg const[0])
ioctl$KBASE_HWCNT_READER_DUMP(fd fd_hwcnt, cmd const[KBASE_HWCNT_READER_DUMP], arg const[0])
ioctl$KBASE_HWCNT_READER_CLEAR(fd fd_hwcnt, cmd const[KBASE_HWCNT_READER_CLEAR], arg const[0])
ioctl$KBASE_HWCNT_READER_GET_BUFFER(fd fd_hwcnt, cmd const[KBASE_HWCNT_READER_GET_BUFFER], arg ptr[out, kbase_hwcnt_reader_metadata])
ioctl$KBASE_HWCNT_READER_PUT_BUFFER(fd fd_hwcnt, cmd const[KBASE_HWCNT_READER_PUT_BUFFER], arg ptr[in, kbase_hwcnt_reader_metadata])
ioctl$KBASE_HWCNT_READER_SET_INTERVAL(fd fd_hwcnt, cmd const[KBASE_HWCNT_READER_SET_INTERVAL], arg intptr)
ioctl$KBASE_HWCNT_READER_ENABLE_EVENT(fd fd_hwcnt, cmd const[KBASE_HWCNT_READER_ENABLE_EVENT], arg const[0])
ioctl$KBASE_HWCNT_READER_DISABLE_EVENT(fd fd_hwcnt, cmd const[KBASE_HWCNT_READER_DISABLE_EVENT], arg const[0])
ioctl$KBASE_HWCNT_READER_GET_API_VERSION(fd fd_hwcnt, cmd const[KBASE_HWCNT_READER_GET_API_VERSION], arg const[0])

type base_atom_id int8

base_jd_atom_v2 {
	jc		int64
	udata		base_jd_udata
	extres_list	int64
	nr_extres	int16
	compat_core_req	int16
	pre_dep		array[base_dependency, 2]
	atom_number	base_atom_id
	prio		flags[base_jd_prio, int8]
	device_nr	int8
	jobslot		int8
	core_req	flags[base_jd_core_req, int32]
	renderpass_id	int8
	padding		array[const[0, int8], 7]
}

base_dependency {
	atom_id		base_atom_id
	dependency_type	flags[base_jd_dep_type, int8]
}

base_jd_udata {
	blob	array[int64, 2]
}

kbase_ioctl_job_submit {
	addr		ptr64[out, array[base_jd_atom_v2]]
	nr_atoms	len[addr, int32]
# sizeof(base_jd_atom_v2)
	stride		const[56, int32]
}

kbase_ioctl_soft_event_update {
	event		gpu_addr
	new_status	int32
	flags		const[0, int32]
}

kbase_ioctl_version_check {
	major	int16
	minor	int16
}

kbase_ioctl_set_flags {
	create_flags	flags[basep_context_create_kernel_flags, int32]
}

kbase_ioctl_get_gpuprops {
	buffer	ptr64[out, array[int8]]
	size	len[buffer, int32]
	flags	const[0, int32]
}

kbase_ioctl_mem_alloc {
	va_pages	int64
	commit_pages	int64
	extent		int64
	flags		flags[base_mem_alloc_flags, int64]
	out_flags	int64	(out_overlay)
	gpu_va		gpu_addr
}

kbase_ioctl_mem_query {
	gpu_addr	gpu_addr
	query		flags[kbase_ioctl_mem_query_flags, int64]
	value		int64	(out_overlay)
}

kbase_ioctl_mem_free {
	gpu_addr	gpu_addr
}

kbase_ioctl_hwcnt_reader_setup {
	buffer_count	int32
	jm_bm		int32
	shader_bm	int32
	tiler_bm	int32
	mmu_l2_bm	int32
}

kbase_ioctl_hwcnt_enable {
	dump_buffer	gpu_addr
	jm_bm		int32
	shader_bm	int32
	tiler_bm	int32
	mmu_l2_bm	int32
}

kbase_ioctl_hwcnt_values {
	data	ptr64[out, array[int8]]
	size	len[data, int32]
	padding	const[0, int32]
}

kbase_ioctl_disjoint_query {
	counter	int32
}

kbase_ioctl_get_ddk_version {
	version_buffer	ptr64[out, array[int8]]
	size		len[version_buffer, int32]
	padding		const[0, int32]
}

kbase_ioctl_mem_jit_init_10_2 {
	va_pages	int64
}

kbase_ioctl_mem_jit_init_11_5 {
	va_pages	int64
	max_allocations	int8
	trim_level	int8
	group_id	int8
	padding		array[const[0, int8], 5]
}

kbase_ioctl_mem_jit_init {
	va_pages	int64
	max_allocations	int8
	trim_level	int8
	group_id	int8
	padding		array[const[0, int8], 5]
	phys_pages	int64
}

kbase_ioctl_mem_sync {
	handle		gpu_addr
	user_addr	user_addr
	size		int64
	type		flags[base_syncset_op_flags, int8]
	padding		array[const[0, int8], 7]
}

kbase_ioctl_mem_find_cpu_offset {
	gpu_addr	gpu_addr
	cpu_addr	user_addr
	size		int64
	offset		int64	(out_overlay)
}

kbase_ioctl_get_context_id {
	id	int32
}

kbase_ioctl_tlstream_acquire {
	flags	int32
}

kbase_ioctl_mem_commit {
	gpu_addr	gpu_addr
	pages		int64
}

kbase_ioctl_mem_alias {
	flags		flags[base_mem_alloc_flags, int64]
	stride		int64
	nents		len[aliasing_info, int64]
	aliasing_info	ptr64[in, array[base_mem_aliasing_info]]

	out_flags	int64	(out_overlay)
	gpu_va		gpu_addr
	va_pages	int64
}

base_mem_aliasing_info {
	handle	gpu_addr
	offset	int64
	length	int64
}

kbase_ioctl_mem_import {
	flags		flags[base_mem_alloc_flags, int64]
	phandle		int64
	type		flags[base_mem_import_type, int32]
	padding		const[0, int32]

	out_flags	int64	(out_overlay)
	gpu_va		gpu_addr
	va_pages	int64
}

kbase_ioctl_mem_flags_change {
	gpu_va	gpu_addr
	flags	flags[base_mem_alloc_flags, int64]
	mask	int64
}

kbase_ioctl_stream_create {
	name	array[int8, 32]
}

kbase_ioctl_fence_validate {
	fd	fd_fence
}

kbase_ioctl_mem_profile_add {
	buffer	ptr64[in, array[int8]]
	len	len[buffer, int32]
	padding	const[0, int32]
}

kbase_ioctl_sticky_resource_map {
	count	len[address, int64]
	address	ptr64[in, array[int64]]
}

kbase_ioctl_sticky_resource_unmap {
	count	len[address, int64]
	address	ptr64[in, array[int64]]
}

kbase_ioctl_mem_find_gpu_start_and_offset {
	gpu_addr	gpu_addr
	size		int64
	start		gpu_addr	(out_overlay)
	offset		int64
}

kbase_ioctl_mem_exec_init {
	va_pages	int64
}

kbase_ioctl_get_cpu_gpu_timeinfo {
	request_flags	flags[base_timerequest_allowed_flags, int32]
	paddings	array[const[0, int8], 7]
	sec		int64	(out_overlay)
	nsec		int32
	padding		int32
	timestamp	int64
	cycle_counter	int64
}

kbase_hwcnt_reader_metadata {
	timestamp	int64
	event_id	int32
	buffer_idx	int32
}

kbase_ioctl_read_user_page {
	offset         const[0x038, int32]
	padding	       const[0, int32]
	val_lo         int32  (out_overlay)
	val_hi         int32
}

kbase_ioctl_mem_alloc_ex {
	va_pages      int64
	commit_pages  int64
	extension     int64
	flags         flags[base_mem_alloc_flags, int64]
	fixed_address gpu_addr
	extra         array[const[0, int64], 3]
	out_flags     int64  (out_overlay)
	gpu_va        gpu_addr
}

kbase_ioctl_cs_cpu_queue_info {
	buffer	ptr64[in, array[int8]]
	size    len[buffer, int64]
}

kbase_ioctl_cs_get_glb_iface {
	max_group_num  		int32
	max_total_stream_num 	int32
	groups_ptr    		ptr64[in, user_addr]
	streams_ptr   		ptr64[in, user_addr]
	glb_version   		int32  (out_overlay)
	features      		int32
	group_num     		int32
	prfcnt_size   		int32
	total_stream_num 	int32
	instr_featurs 		int32
}

kbase_ioctl_cs_tiler_heap_term {
	gpu_heap_va	gpu_addr
}

kbase_ioctl_cs_tiler_heap_init_1_13 {
	chunk_size		int32
	initial_chunks		int32
	max_chunks		int32
	target_in_flight	int16
	group_id		int8
	padding			const[0, int8]
	gpu_heap_va		gpu_addr  (out_overlay)
	first_chunk_va		gpu_addr
}


kbase_ioctl_cs_tiler_heap_init {
	chunk_size		int32
	initial_chunks		int32
	max_chunks		int32
	target_in_flight	int16
	group_id		int8
	padding			const[0, int8]
	buf_desc_va		gpu_addr
	gpu_heap_va		gpu_addr (out_overlay)
	first_chunk_va		gpu_addr
}

# LIZ TODO: originally uint8, too small. Check al uint.
kbase_ioctl_kcpu_queue_new {
	id			int16[0:256]
	pad			array[const[0, int8], 7]
}

# LIZ TODO: originally uint8, too small.
kbase_ioctl_kcpu_queue_delete {
	id			int16[0:256]
	pad			array[const[0, int8], 7]
}

# addr			ptr64[out, array[kbase_kcpu_command_queue]]
# LIZ TODO: originally uint8, too small. Check al uint.
kbase_ioctl_kcpu_queue_enqueue {
	addr			ptr64[out, gpu_addr]
	nr_commands		len[addr, int32]
	id			int16[0:256]
	padding			array[const[0, int8], 3]
}

# kbase_kcpu_command_queue {
# 	# LIZ TODO: Not sure how to create queue:
# 	# mali_kbase/csf/mali_kbase_csf_kcpu.h:279
# 	# Includes mutex. Potentially can get from kcpu_queue_new
# }

kbase_ioctl_cs_queue_terminate  {
	buffer_gpu_addr		ptr64[in, array[int8]]
}

kbase_ioctl_cs_queue_group_create [
	in kbase_ioctl_cs_queue_group_create_in
	out kbase_ioctl_cs_queue_group_create_out
] [varlen]

kbase_ioctl_cs_queue_group_create_in {
	tiler_mask		int64
	fragment_mask		int64
	compute_mask		int64
	cs_min			int8
	priority		int8
	tiler_max		int8
	fragment_max		int8
	compute_max		int8
	csi_handlers		flags[csf_csi_flags, int8]
	padding			array[const[0, int8], 2]
	reserved		int64
}

kbase_ioctl_cs_queue_group_create_out {
	group_handle		int8
	padding			array[const[0, int8], 3]
	group_uid		int32
}

kbase_ioctl_cs_queue_group_create_1_6 [
	in kbase_ioctl_cs_queue_group_create_1_6_in
	out kbase_ioctl_cs_queue_group_create_1_6_out
] [varlen]

kbase_ioctl_cs_queue_group_create_1_6_in {
	tiler_mask		int64
	fragment_mask		int64
	compute_mask		int64
	cs_min			int8
	priority		int8
	tiler_max		int8
	fragment_max		int8
	compute_max		int8
	padding			array[const[0, int8], 2]
	reserved		int64
}

kbase_ioctl_cs_queue_group_create_1_6_out {
	group_handle		int8
	padding			array[const[0, int8], 3]
	group_uid		int32
}

#LIZ TODO: Check offset values.
kbase_ioctl_cs_queue_register_ex {
	buffer_gpu_addr		ptr64[in, array[int8]]
	buffer_size		len[buffer_gpu_addr, int32]
	priority		int8
	padding			array[const[0, int8], 3]
	ex_offset_var_addr	gpu_addr
	ex_buffer_base		ptr64[in, array[int8]]
	ex_buffer_size		len[buffer_gpu_addr, int32]
	ex_event_size		int8
	ex_event_state		int8
	ex_padding		array[const[0, int8], 2]
}

kbase_ioctl_cs_queue_bind [
	in			kbase_ioctl_cs_queue_bind_in
	out			kbase_ioctl_cs_queue_bind_out
]

# LIZ TODO: originally uint8, too small. Check al uint.
kbase_ioctl_cs_queue_bind_in {
	buffer_gpu_addr		ptr64[in, array[int8]]
	group_handle		int16[0:256]
	csi_index		int8
	padding			array[const[0, int8], 6]
}

kbase_ioctl_cs_queue_bind_out {
	mmap_handle		int64
}

kbase_ioctl_cs_queue_kick {
	buffer_gpu_addr		ptr64[in, array[int8]]
}

base_ioctl_cs_queue_register {
	buffer_gpu_addr		ptr64[in, array[int8]]
	buffer_size		len[buffer_gpu_addr, int32]
	priority		int8
	padding			array[const[0, int8], 6]  (out_overlay)
}

# LIZ TODO: buffer_size check array length
kbase_ioctl_buffer_liveness_update {
	live_ranges_address	ptr64[in, array[user_addr]]
	live_ranges_count	len[live_ranges_address, int64]
	buffer_va_address	ptr64[in, array[int8]]
	buffer_sizes_address	ptr64[in, array[int64]]
	buffer_count		len[buffer_va_address, int64]
}

# LIZ TODO: check item count/size
kbase_ioctl_kinstr_prfcnt_setup {
	request_item_count		len[requests_ptr, int32]
	request_item_size		bytesize[requests_ptr, int32]
	requests_ptr			ptr64[in, prfcnt_request_item]
	prfcnt_metadata_item_size	int32	(out_overlay)
	prfcnt_mmap_size_bytes		int32
}

prfcnt_request_item {
	hdr	prfcnt_request_item_header
	u	prfcnt_request_union
}

# LIZ TODO: Check possible item_versions
prfcnt_request_item_header {
	item_type	flags[prfcnt_request_item_type, int16]
	item_version	const[0, int16]
}

prfcnt_request_union [
	req_mode	prfcnt_request_mode
	req_enable	prfcnt_request_enable
	req_scope	prfcnt_request_scope
] [varlen]

prfcnt_request_mode {
	mode 		flags[prfcnt_mode, int8]
	pad		array[const[0, int8], 7]
	mode_config	prfcnt_request_mode_union
}

prfcnt_request_mode_union [
	periodic	periodic_config
]

periodic_config {
	period_ns	int64
}

# LIZ TODO: check item count/size
prfcnt_request_enable {
	block_type	flags[prfcnt_block_type, int8]
	set		flags[prfcnt_set, int8]
	pad		array[const[0, int8], 6]
	enable_mask     array[int64, 2]
}

prfcnt_request_scope {
	scope		flags[prfcnt_scope, int8]
	pad		array[const[0, int8], 7]
}

kbase_ioctl_kinstr_prfcnt_enum_info {
	info_item_size  	len[info_list_ptr, int32]
	info_item_count		bytesize[info_list_ptr, int32]
	info_list_ptr		prfcnt_enum_item
}

prfcnt_enum_item {
	hdr 	prfcnt_enum_item_header
	u	prfcnt_enum_union
}

#LIZ TODO: Check possible item_versions
prfcnt_enum_item_header {
	item_type	flags[prfcnt_request_item_type, int16]
	item_version	const[0, int16]
}

prfcnt_enum_union [
	block_counter	prfcnt_enum_block_counter
	request		prfcnt_enum_request
	sample_info	prfcnt_enum_sample_info
] [varlen]

prfcnt_enum_block_counter {
	block_type	flags[prfcnt_block_type, int8]
	set		flags[prfcnt_set, int8]
	pad		array[const[0, int8], 2]
	num_instances   int16
	num_values      int16
	counter_mask	array[int64, 2]
}

# LIZ TODO: Check possible versions for version_mask. Potentially 0x1
prfcnt_enum_request {
	request_item_type	flags[prfcnt_request_enum_type, int16]
	pad			const[0, int16]
	versions_mask   	const[0, int32]
}

prfcnt_enum_sample_info {
	num_clock_domains	int32
	pad			const[0, int32]
}

kbase_ioctl_set_limited_core_count {
	max_core_count		int8
}

kbase_ioctl_context_priority_check {
	priority		int8
}

# BASE_CSF_TILER_OOM_EXCEPTION_FLAG(1u << 0)=1
csf_csi_flags = 1
# LIZ TODO: From mali_kbase/mali_kbase_kinstr_prfcnt.c:1708; include NONE?
prfcnt_request_enum_type = PRFCNT_ENUM_TYPE_BLOCK, PRFCNT_ENUM_TYPE_REQUEST, PRFCNT_ENUM_TYPE_SAMPLE_INFO
prfcnt_request_item_type = PRFCNT_REQUEST_TYPE_MODE, PRFCNT_REQUEST_TYPE_ENABLE, PRFCNT_REQUEST_TYPE_SCOPE
# 255 is the "RESERVED" flag
prfcnt_scope = PRFCNT_SCOPE_GLOBAL, 255
prfcnt_set = PRFCNT_SET_PRIMARY, PRFCNT_SET_SECONDARY, PRFCNT_SET_TERTIARY, 255
prfcnt_block_type = PRFCNT_BLOCK_TYPE_FE, PRFCNT_BLOCK_TYPE_TILER, PRFCNT_BLOCK_TYPE_MEMORY, PRFCNT_BLOCK_TYPE_SHADER_CORE, 255
prfcnt_mode = PRFCNT_MODE_MANUAL, PRFCNT_MODE_PERIODIC, 255
base_jd_dep_type = BASE_JD_DEP_TYPE_INVALID, BASE_JD_DEP_TYPE_DATA, BASE_JD_DEP_TYPE_ORDER
base_jd_prio = BASE_JD_PRIO_MEDIUM, BASE_JD_PRIO_HIGH, BASE_JD_PRIO_LOW
base_jd_core_req = BASE_JD_REQ_DEP, BASE_JD_REQ_FS, BASE_JD_REQ_CS, BASE_JD_REQ_T, BASE_JD_REQ_CF, BASE_JD_REQ_V, BASE_JD_REQ_FS_AFBC, BASE_JD_REQ_EVENT_COALESCE, BASE_JD_REQ_COHERENT_GROUP, BASE_JD_REQ_PERMON, BASE_JD_REQ_EXTERNAL_RESOURCES, BASE_JD_REQ_SOFT_JOB, BASE_JD_REQ_ONLY_COMPUTE, BASE_JD_REQ_SPECIFIC_COHERENT_GROUP, BASE_JD_REQ_EVENT_ONLY_ON_FAILURE, BASE_JD_REQ_SKIP_CACHE_START, BASE_JD_REQ_SKIP_CACHE_END, BASE_JD_REQ_JOB_SLOT, BASE_JD_REQ_START_RENDERPASS, BASE_JD_REQ_END_RENDERPASS
kbase_ioctl_mem_query_flags = KBASE_MEM_QUERY_COMMIT_SIZE, KBASE_MEM_QUERY_VA_SIZE, KBASE_MEM_QUERY_FLAGS
base_syncset_op_flags = BASE_SYNCSET_OP_MSYNC, BASE_SYNCSET_OP_CSYNC
# 0x400000-0x2000000 are individual bits of BASE_MEM_GROUP_ID_MASK
base_mem_alloc_flags = BASE_MEM_PROT_CPU_RD, BASE_MEM_PROT_CPU_WR, BASE_MEM_PROT_GPU_RD, BASE_MEM_PROT_GPU_WR, BASE_MEM_PROT_GPU_EX, BASEP_MEM_PERMANENT_KERNEL_MAPPING, BASE_MEM_GPU_VA_SAME_4GB_PAGE, BASEP_MEM_NO_USER_FREE, BASE_MEM_RESERVED_BIT_8, BASE_MEM_GROW_ON_GPF, BASE_MEM_COHERENT_SYSTEM, BASE_MEM_COHERENT_LOCAL, BASE_MEM_CACHED_CPU, BASE_MEM_SAME_VA, BASE_MEM_NEED_MMAP, BASE_MEM_COHERENT_SYSTEM_REQUIRED, BASE_MEM_PROTECTED, BASE_MEM_DONT_NEED, BASE_MEM_IMPORT_SHARED, BASE_MEM_RESERVED_BIT_19, BASE_MEM_TILER_ALIGN_TOP_EXTENT_MAX_PAGES, BASE_MEM_TILER_ALIGN_TOP, BASE_MEM_UNCACHED_GPU, 0x400000, 0x800000, 0x1000000, 0x2000000, BASE_MEM_IMPORT_SYNC_ON_MAP_UNMAP, BASE_MEM_FLAG_MAP_FIXED
base_mem_import_type = BASE_MEM_IMPORT_TYPE_INVALID, BASE_MEM_IMPORT_TYPE_UMM, BASE_MEM_IMPORT_TYPE_USER_BUFFER
# 0x08-0x20 are individual bits of BASEP_CONTEXT_MMU_GROUP_ID_MASK
basep_context_create_kernel_flags = BASE_CONTEXT_SYSTEM_MONITOR_SUBMIT_DISABLED, 0x8, 0x10, 0x20, 0x40
base_timerequest_allowed_flags = BASE_TIMEINFO_MONOTONIC_FLAG, BASE_TIMEINFO_TIMESTAMP_FLAG, BASE_TIMEINFO_CYCLE_COUNTER_FLAG, BASE_TIMEINFO_KERNEL_SOURCE_FLAG, BASE_TIMEINFO_USER_SOURCE_FLAG
